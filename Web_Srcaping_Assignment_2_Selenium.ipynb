{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING(Using Selenium) ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping data for “Data Analyst” Job position in “Bangalore” location from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required library\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.naukri.com/'\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar and entering Data Analyst in search bar\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location bar and entering Bangalore in location bar\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using xpath fn\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to scrap job details\n",
    "job_titles =[]\n",
    "company_names=[]\n",
    "Exp_list=[]\n",
    "loc_list=[]\n",
    "Package_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrating title tag, company tag, experience tag, location tag, package tag then the text of the job titls is inside the tags are extrated above \n",
    "# we will run a loop to itearate over the tags extracted above and extarct the text inside them\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[0:10]:\n",
    "        job_titles.append(i.text.replace('\\n','').strip())\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[0:10]:\n",
    "        company_names.append(j.text.replace('\\n','').strip())\n",
    "for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")[0:10]:\n",
    "        Exp_list.append(k.text.replace('\\n','').strip())\n",
    "for m in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")[0:10]:\n",
    "        loc_list.append(m.text.replace('\\n','').strip())\n",
    "for n in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")[0:10]:\n",
    "        Package_list.append(n.text.replace('\\n','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(Exp_list),len(loc_list),len(Package_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Data_Analyst_jobs=pd.DataFrame({})\n",
    "Data_Analyst_jobs['title']=job_titles\n",
    "Data_Analyst_jobs['company']=company_names\n",
    "Data_Analyst_jobs['experience_required']= Exp_list\n",
    "Data_Analyst_jobs['location']=loc_list\n",
    "Data_Analyst_jobs['Package']=Package_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "      <th>Package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate Systems and Data Analyst</td>\n",
       "      <td>Boeing</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consultant-Data Analyst -Bangalore</td>\n",
       "      <td>Innovsource Services Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst @ Flipkart on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deputy Manager - Data Analyst</td>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst / Business Analyst -</td>\n",
       "      <td>LatentView Analytics Private Limited</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>ALSTOM India Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0               Associate Systems and Data Analyst   \n",
       "1               Consultant-Data Analyst -Bangalore   \n",
       "2  Data Scientist / Data Analyst -Business Analyst   \n",
       "3                                     Data Analyst   \n",
       "4   Hiring For Data Analyst @ Flipkart on Contract   \n",
       "5                                     Data Analyst   \n",
       "6                    Deputy Manager - Data Analyst   \n",
       "7                              Senior Data Analyst   \n",
       "8                Data Analyst / Business Analyst -   \n",
       "9                            Business Data Analyst   \n",
       "\n",
       "                                company experience_required  \\\n",
       "0                                Boeing             0-4 Yrs   \n",
       "1  Innovsource Services Private Limited             2-7 Yrs   \n",
       "2    Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "3     Flipkart Internet Private Limited             1-3 Yrs   \n",
       "4     Flipkart Internet Private Limited             2-6 Yrs   \n",
       "5                IBM India Pvt. Limited             3-7 Yrs   \n",
       "6    Schneider Electric India Pvt. Ltd.             3-6 Yrs   \n",
       "7     Flipkart Internet Private Limited             2-5 Yrs   \n",
       "8  LatentView Analytics Private Limited             1-5 Yrs   \n",
       "9                  ALSTOM India Limited            5-10 Yrs   \n",
       "\n",
       "                                            location                  Package  \n",
       "0                                Bangalore/Bengaluru            Not disclosed  \n",
       "1                                Bangalore/Bengaluru            Not disclosed  \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  3,50,000 - 4,50,000 PA.  \n",
       "3                                Bangalore/Bengaluru            Not disclosed  \n",
       "4                                Bangalore/Bengaluru            Not disclosed  \n",
       "5                                Bangalore/Bengaluru            Not disclosed  \n",
       "6                                Bangalore/Bengaluru            Not disclosed  \n",
       "7                                Bangalore/Bengaluru            Not disclosed  \n",
       "8                       Chennai, Bangalore/Bengaluru            Not disclosed  \n",
       "9                                Bangalore/Bengaluru            Not disclosed  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " scraping data for “Data Scientist” Job position in “Bangalore” location from naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing exceptional handling library\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.naukri.com/'\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar and entering Data Scientist in job search bar\n",
    "search_job2 = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job2.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location bar and entering bangalore in search location bar\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\") \n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using xpath fn\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for company name, experience and location\n",
    "company_names=[]\n",
    "Exp_list=[]\n",
    "loc_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extrating title tag, company tag, experience tag, location tag then the text of the job titls is inside the tags are extrated above \n",
    "# we will run a loop to itearate over the tags extracted above and extarct the text inside them\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[0:10]:\n",
    "        company_names.append(j.text.replace('\\n','').strip())\n",
    "for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")[0:10]:\n",
    "        Exp_list.append(k.text.replace('\\n','').strip())\n",
    "for m in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")[0:10]:\n",
    "        loc_list.append(m.text.replace('\\n','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-scientist-fractal-analytics-ltd-mumbai-gurgaon-gurugram-bangalore-bengaluru-4-to-8-years-240521501478?src=jobsearchDesk&sid=16222854470823868&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-fractal-analytics-pvt-ltd-gurgaon-gurugram-bangalore-bengaluru-mumbai-all-areas-5-to-10-years-240521007717?src=jobsearchDesk&sid=16222854470823868&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-persistent-systems-limited-hyderabad-secunderabad-pune-bangalore-bengaluru-8-to-13-years-260521006008?src=jobsearchDesk&sid=16222854470823868&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-wipro-limited-kolkata-hyderabad-secunderabad-chennai-bangalore-bengaluru-4-to-9-years-210521000038?src=jobsearchDesk&sid=16222854470823868&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-looking-for-data-scientist-for-infogain-infogain-india-p-ltd-noida-bangalore-bengaluru-mumbai-all-areas-10-to-20-years-280521000845?src=jobsearchDesk&sid=16222854470823868&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-matlab-machine-learning-algorithms-wrackle-technologies-pvt-ltd-bangalore-bengaluru-3-to-8-years-161220907168?src=jobsearchDesk&sid=16222854470823868&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-machine-learning-augmatrixgo-bangalore-bengaluru-2-to-5-years-140121905423?src=jobsearchDesk&sid=16222854470823868&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-oracle-india-pvt-ltd-bangalore-bengaluru-6-to-10-years-190521008276?src=jobsearchDesk&sid=16222854470823868&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-data-scientist-on-contract-basis-3-6-months-globaledx-learning-and-technology-solution-pvt-ltd-hyderabad-secunderabad-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-170521003581?src=jobsearchDesk&sid=16222854470823868&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-profitwheel-data-technologies-private-limited-hyderabad-secunderabad-bangalore-bengaluru-mumbai-all-areas-2-to-4-years-240521006055?src=jobsearchDesk&sid=16222854470823868&xp=10&px=1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[0:10]:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrating joob title and job description\n",
    "job_title=[]\n",
    "job_description=[]\n",
    "for i in urls[0:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    #fetching job title\n",
    "    try:\n",
    "        job=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_title.append(job.text.replace('\\n','').strip())\n",
    "    except NoSuchElementException:\n",
    "        job_title.append('-')\n",
    "        \n",
    "    #fetching job description\n",
    "    try:\n",
    "        job_desc=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_description.append(job_desc.text.replace('\\n','').strip())\n",
    "    except NoSuchElementException:\n",
    "        job_description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))\n",
    "print(len(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job descriptionJob Responsibilities:Work with product managers and clients to better understand the business problemThink through a business problem and come up with a set of hypothesesCreate a list of potentially relevant supporting data elementsWork with data engineers and/or data analysts to procure data and test it for problemsCollaborate with other Data ScientistsPropose modeling approachesMine the data to check completeness, value distributions, etc.Data imputation and feature engineeringTest data for signalRun feature selectionTune the modelSet up tests for the model healthCollaborate with product managers to find the best way to present the resultsWork with developers on productionizing modelsMust HaveA minimum of 6 years of post-academic experience developing advanced analytics and applying data science in a business environmentExperience in data mining techniques and methodologies (data prep/modeling, classification, regression, clustering, causal modeling, AI, machine learning, ensemble approaches)Experience developing in Python within a production environmentAdvanced experience in data visualization tools with a strong grasp of effective data modeling and visualization practicesThe ability to rapidly develop proof of concepts and test new ideas, as well as the ability to scale these ideas into production ready models that can be deployed within our organizationExamples of how your passion for data driven decision making and intellectual curiosity translated in to value for your organizationNice to HaveAn advanced Degree (Masters or PhD) in engineering, mathematics, physics, economics, computer science, statistics, or business analytics orExperience leveraging cloud platforms such as Amazon Web Services (AWS) and Google Cloud Platform (GCP)Strong research skills and the ability to put emerging ideas into practiceRoleTechnical ArchitectIndustry TypeManagement ConsultingFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryProgramming & DesignEducationUG :Any Graduate in Any SpecializationPG :Post Graduation Not RequiredKey SkillsComputer scienceGCPData modelingArtificial IntelligenceBusiness analyticsMachine learningData miningAWSPythonTesting',\n",
       " 'Job descriptionPosition Description:The Artificial Intelligence and Machine Learning (AIML) group at Fractal Analytics is actively involved in helping Fortune 500 companies by enabling them to discover how they can leverage their data using advanced and sophisticated AI/ML algorithms for which we are looking for Data Scientists with the capability to work on independent statistical and machine learning research/ projects. If you are a problem solver with a curiosity for exploring new techniques and technologies in AIML space, then we would like to talk with you.Job Responsibilities:Ability to understand a problem statement and implement analytical solutions & techniques independently with independently/proactively/thought-leadershipWork with stakeholders throughout the organization to identify opportunities for leveraging company/client data to drive business solutionsFast learner: ability to learn and pick up a new language/tool/ platform quicklyConceptualize, design, and deliver high-quality solutions and insightful analysisConduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problemsCollaborate and coordinate with different functional teams (engineering and product development) to implement models and monitor outcomesAbility to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer Segmentation & Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price OptimizationExperience Required:Minimum 3+ years of experience in Machine Learning domainExpert level proficiency in at least one of R and PythonAbility to create efficient solutions to complex problems. Strong skills in data-structures and ML algorithmsExperience of working on end-to-end data science pipeline: problem scoping, data gathering, EDA, modelling, insights, visualizations, monitoring and maintenanceProblem-solving: Ability to break the problem into small parts and applying relevant techniques to drive required outcomesIntermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basisWe use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modeling, dimensionality reduction, SEM, GLM, GLMM, clustering, Deep learning etc. on a regulabasis. If you know few of them you are good to goGood to Have:Experience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systemsExperience of working in on one or more domains:CPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain managementBFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detectionHealthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuseExperience in working with Linux computing environment and use of command line tools like sed/awkGood grasp on databases including RDBMS, NoSQL, MongoDB etc.Education Qualification:B.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields from one of the premier Institutes (IITs/NITs/BITS)Do write back if you would be interested in the same.RoleTeam Lead/Technical LeadIndustry TypeMiscellaneousFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryProgramming & DesignEducationUG :B.Tech/B.E. in Any SpecializationKey SkillsSASMachine LearningPythonRNoSQLArtificial IntelligenceData StructuresGoSupply Chain ManagementData AnalyticsAWSDeep LearningSkills highlighted with ‘‘ are preferred keyskills',\n",
       " '-',\n",
       " 'Job descriptionRole: Data ScientistRoles and ResponsibilitiesSuitable candidates will be part of Wipro Digital-Intelligent Enterprise practice. The role entails leveraging Data Science and Machine Learning to solve typical problems within an organization and create IP that could be deployed in a productized mode. This will entail significant hands-on work on multiple Big Data Technologies, Data Analysis, Identifying data patterns, ML models, Insights generation. The role entails deployment in a customer context and managing customer expectations.Technical Skills Required:Hands on with Python or RAnalytics using industry leading BI tools and technologiesImplementation knowledge of supervised\\\\un-supervised machine learning algorithmsGood statistical analysis skills for data pre-processing and data wranglingExperienced in using big data frameworks like HadoopKnowledge of business intelligence tools or reporting toolsData Preparation for ModelingMissing Data Imputation,Outlier TreatmentScaling, Normalization, StandardizationEncoding for Categorical VariablesOversampling\\\\Undersampling for reducing class imbalanceExperience in building solutions using Model LibraryFeature SelectionTree-based Ensemble ModelsGradient\\\\Adaptive Boosted TreesHyper-parameter tuningBuilding Prediction mechanisms using methods like Logistic regression, voting classifier stacking etcRoleSoftware DeveloperIndustry TypeIT Services & ConsultingFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryProgramming & DesignEducationUG :B.Tech/B.E. in Any SpecializationKey SkillsData ScienceMachine LearningPythonLogistic RegressionData WranglingHadoopData AnalysisBig DataStatistical AnalysisSkills highlighted with ‘‘ are preferred keyskills',\n",
       " \"Job descriptionDear CandidatesWe are looking for an Experienced Data Scientist Architect for our organization Infogain, Please find below the Company Description and JD for the same below.Our office location is at:1, Seepz Rd A, Seepz, Andheri East, Mumbai, Maharashtra 400096B, Aundh IT Park, Bhau Patil Marg, Pragati Nagar, Bopodi, Pune, Maharashtra 411020(Acquired Company)No.90B, ELCITA PID No. 295 of Konappa Agrahara, Electronic City, 1st Phase, Bengaluru 560 100, Karnataka StateNoida- Sector 60 Gautam Budh Nagar UP.Please Note: We have our office located only in the above locations mentioned. No Cabs are provided.Company description:Infogain is a global business oriented IT consulting provider of front-end, customer-facing technologies, processes and applications, leading to a more efficient and streamlined customer experience for enterprises in the US, Europe, the Middle East, Asia Pacific and India. Offering solutions for the high-tech, retail, insurance and travel & hospitality verticals, Infogain specializes in digital transformation, ERP, CRM, software product engineering, knowledge management, cloud services, and mobility. Infogain has strong partnerships with industry leaders including Microsoft, Oracle and Salesforce. Headquartered in Californias Silicon Valley, Infogain has close to 5,000 employees providing consulting, technology and digital transformation services to clients around the globe.Visit us online at www.infogain.comRoles and ResponsibilitiesRole: Data ScientistExperience: 10+ yearsLocation NCR/Bangalore/ Mumbai/PuneAs an data scientist, the candidate should be able to lead and deliver the end-to-end data science projects and should be able to frontend with the clients. Strong exposure to AI/ML space with hosted model (Azure, AWS, or Google).Primary Responsibilities:Deep learning experience with Tensor flow and Kera's or Pytorch is mustExperience with the following is preferredDifferent data processing libraries such as Numpy, SciPy, Pandas, Matplotlib, Scikit-learnExperience with one or more general purpose programming languages including but not limited to: Python (Must), R, Java, or C/C++.Different neural Networks ANN, CNN, RNN, LSTM, Transformer Based models, GAN, Reinforcement LearningFamiliarity with different model architectures AlexNet, ResNet, MobileNet etc., in Computer Vision & BiLSTM, Bert family models.Experience with distribution strategies for data and model parallelismDevelopment of mobile applications with tensor flow (TF Lite)Experience in the development of End-to-end production-based models. Cloud deployment of any machine learning models.Understanding of advanced machine learning data pipelines components including Data Versioning, Code Versioning, Solution Versioning, Drift detection, Model Interpretability & explainability.Experience with Structured Data Machine Learning techniquesUsed AutoML techniques.Worked or knowledge on distributed computing example Spark.Experience with open source systems such as MLFlow, DVC, PyCaret, Prophet etc.Additional Responsibilities:Experience in digital marketing or marketing is a plusShould be well versed with Cloud Platforms (AWS, Azure, GCP) and their EcosystemExpected to partner with other 3rd party vendors, customer touch points (Application, Data and Infrastructure Architects) to deliver best in class solutionsShould have Good architecture experience in applications development in a complex, multi-platform distributed environment.Education:BE or MS or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or a related technical field.Experience:6 + years of overall Experience4+ years in overall AI and ML experience with pythonPerks and BenefitsEmail your resume on: anoushka.goyal@infogain.comRoleIT/Technical Content DeveloperIndustry TypeIT Services & ConsultingFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryOtherEducationUG :B.Tech/B.E. in Any SpecializationPG :MS/M.Sc(Science) in Any SpecializationDoctorate :Ph.D in ComputersKey SkillsPytorchArtificial IntelligencePythonTensorflowCnnRnnLstmNeural NetworksReinforcement LearningComputer VisionSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job descriptionRoles and ResponsibilitiesData Scientist - Data Mining/Machine Learning/Statistical AnalysisRequirements :- 3-9 years of strong experience in data mining, machine learning, and statistical analysis.- BS/MS/Ph.D. in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)- Ability to lead and deliver in a fast-paced start-up environment.- Fluency in tools such as Matlab, Python, etc.- Strong intuition for data and Keen aptitude on large scale data analysis- Excellent written and verbal communication skills.- Ability to collaborate across teams and strong interpersonal skills.RoleData AnalystIndustry TypeIT Services & ConsultingFunctional AreaAnalytics & Business IntelligenceEmployment TypeFull Time, PermanentRole CategoryAnalytics & BIEducationUG :B.Sc in Maths, Computers, StatisticsPG :MS/M.Sc(Science) in Computers, Statistics, MathsDoctorate :Ph.D in Statistics, Computers, Maths, Doctorate Not RequiredKey SkillsData ScienceData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " 'Job descriptionRoles and Responsibilities- Selecting features, building and optimizing classifiers using machine learning techniques- Data mining using state-of-the-art methods- Enhancing data collection procedures to include information that is relevant for building analytic systems- Processing, cleansing, and verifying the integrity of data used for analysis- Doing ad-hoc analysis and presenting results in a clear manner- Creating automated anomaly detection systems and constant tracking of its performanceSkills Required :- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable- Proficiency in using query languages such as SQL, Hive, Pig- Good applied statistics skills, such as distributions, statistical testing, regression, etc.- Good scripting and programming skills- Data-oriented personality- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITSRoleData AnalystIndustry TypeIT Services & ConsultingFunctional AreaAnalytics & Business IntelligenceEmployment TypeFull Time, PermanentRole CategoryAnalytics & BIEducationUG :B.Tech/B.E. in Any SpecializationPG :M.Tech in Any SpecializationDoctorate :Doctorate Not RequiredKey SkillsHiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig',\n",
       " '-',\n",
       " 'Job descriptionDear Aspirant,Greetings from GlobaledxRoles and ResponsibilitiesExperience : 3+ YearsCTC : Best in MarketLocation : Pan IndiaContract Period : 3-6 MonthsSkill : Python, NLP, Machine Learning Models, Data ScientistInterested, please share your updated resume to hr@globaledx.comOr Call /Whatsapp at Sowjanya : 9505072408Please share with your friends for more reach!RoleIT/Technical Content DeveloperIndustry TypeIT Services & ConsultingFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryOtherEducationUG :Any Graduate in Any SpecializationKey SkillsPostgresqlDATA SCIENTISTMachine LearningScikit-LearnsqlpandasNLPoptimal codingRundeckmachine learning modelslogging frameworkshtmlNUMPYPython',\n",
       " 'Job descriptionROLE & RESPONSIBILITIESA sole contributor in his/her capacity, would be responsible for the following job roles:Formulates and leads guided, multifaceted analytic studies against large volumes of data.Interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific method.Implement new statistical or other mathematical methodologies as needed for specific models or analysisOptimize joint development efforts through appropriate database use and project designCoordinates research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.Experiments against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.Leads all data experiments tasked to the Data Science Team.Coordinates with Data Engineers to build data environments providing data identified by Data Analysts, Data Integrators, Knowledge Managers, and Intel Analysts.Develops methodology and processes for prioritization and scheduling of projects.Analyzes problems and determines root causes.Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.Desired Candidate ProfileSkillsImplement new statistical or other mathematical methodologies as needed for specific models or analysisOptimize joint development efforts through appropriate database use and project designExcellent understanding of machine learning techniques and algorithms, such AS K-nn, naive bayes, SVM, decision forests, etc.Experience with common data science toolkits, such as R, Weka, NUMPY, MATLAB, etc excellence in at least one of these is highly desirableGreat COMMUNICATION SKILLSExperience with data visualisation tools, such as d3.JS, GGPLOT, ETC.Proficiency in using query languages such as SQL, HIVE, PIGExperience with NoSQL databases, such as MONGODB, Cassandra, HBASEQualification CriteriaBSc-IT, BE Graduate/MSC-IT/MCA/BCA/MCMWell-versed in software engineering principles, frameworks and technologiesStrong oral and written communication skillsStrong visual and logical reasoning and ability to work on complex projectsVersatility, flexibility and willingness to work with changing prioritiesMust have Skills3 Years of experience with Data Science as a profession2 years of experience in Data Analytics and building inhouse tools for Data Storage / Analysis / ETL / ALGORITHM Matching / Statistical ModellingShould have at least 2 years of experience working with Python/ PERL/ C++/ Machine Language.Should have experience on working on AdTech/Mar-tech solutionsShould have at least 2 years of experience with SQL, Reporting Systems, Analytics EngineMust have worked with R StudioPreferred SkillsGood knowledge of Core PYTHONKnowledge and experience with Go Lang is an added advantageKnowledge and experience of HTML5, CCS and JavascriptKnowledge of JAVA and Docker will be an added advantage.Perks and BenefitsSalary no bar for the right candidateGreat culture to work withInteraction with Industry Leaders as StakeholdersPilot Team benefits - Long term fitment for the right personnelRoleSystem AnalystIndustry TypeAdvertising & MarketingFunctional AreaIT Software - Application Programming, MaintenanceEmployment TypeFull Time, PermanentRole CategoryProgramming & DesignEducationUG :BCA in Computers, B.Tech/B.E. in Computers, B.Sc in Computers, StatisticsPG :MCA in Computers, M.Tech in Computers, MS/M.Sc(Science) in Computers, M.A in StatisticsKey SkillsPredictive ModelingData ScienceStatistical ModelingMultivariate AnalysisLogistic RegressionSASCouchbaseBig DataNeural NetworksRedisMachine LearningGoogle BigqueryRabbitmqRData AnalyticsStatistical AnalysisElastic SearchPythonCluster AnalysisSkills highlighted with ‘‘ are preferred keyskills']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Framing dataset\n",
    "import pandas as pd\n",
    "Data_Scientist_jobs=pd.DataFrame({})\n",
    "Data_Scientist_jobs['title']=job_title\n",
    "\n",
    "Data_Scientist_jobs['Description']=job_description\n",
    "Data_Scientist_jobs['company_name']=company_names\n",
    "Data_Scientist_jobs['experience_required']= Exp_list\n",
    "Data_Scientist_jobs['location']=loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Description</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Job descriptionJob Responsibilities:Work with ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Job descriptionPosition Description:The Artifi...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Persistent Systems Limited.</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Job descriptionRole: Data ScientistRoles and R...</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking For Data Scientist For Infogain</td>\n",
       "      <td>Job descriptionDear CandidatesWe are looking f...</td>\n",
       "      <td>Infogain India (P) Ltd.</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "      <td>Noida(Sector-60 Noida), Bangalore/Bengaluru(El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python/MATLAB/Machine Learnin...</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesData ...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Job descriptionRoles and Responsibilities- Sel...</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>Job descriptionDear Aspirant,Greetings from Gl...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Job descriptionROLE &amp; RESPONSIBILITIESA sole c...</td>\n",
       "      <td>PROFITWHEEL DATA TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                              Senior Data Scientist   \n",
       "2                                                  -   \n",
       "3                                     Data Scientist   \n",
       "4            Looking For Data Scientist For Infogain   \n",
       "5  Data Scientist - Python/MATLAB/Machine Learnin...   \n",
       "6                  Data Scientist - Machine Learning   \n",
       "7                                                  -   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9                                Lead Data Scientist   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Job descriptionJob Responsibilities:Work with ...   \n",
       "1  Job descriptionPosition Description:The Artifi...   \n",
       "2                                                  -   \n",
       "3  Job descriptionRole: Data ScientistRoles and R...   \n",
       "4  Job descriptionDear CandidatesWe are looking f...   \n",
       "5  Job descriptionRoles and ResponsibilitiesData ...   \n",
       "6  Job descriptionRoles and Responsibilities- Sel...   \n",
       "7                                                  -   \n",
       "8  Job descriptionDear Aspirant,Greetings from Gl...   \n",
       "9  Job descriptionROLE & RESPONSIBILITIESA sole c...   \n",
       "\n",
       "                                        company_name experience_required  \\\n",
       "0                                  Fractal Analytics             4-8 Yrs   \n",
       "1                                  Fractal Analytics            5-10 Yrs   \n",
       "2                        Persistent Systems Limited.            8-13 Yrs   \n",
       "3                                      Wipro Limited             4-9 Yrs   \n",
       "4                            Infogain India (P) Ltd.           10-20 Yrs   \n",
       "5                       Wrackle Technologies Pvt Ltd             3-8 Yrs   \n",
       "6                                        AugmatrixGo             2-5 Yrs   \n",
       "7                             Oracle India Pvt. Ltd.            6-10 Yrs   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...             3-8 Yrs   \n",
       "9      PROFITWHEEL DATA TECHNOLOGIES PRIVATE LIMITED             2-4 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "1  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...  \n",
       "2  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "3  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "4  Noida(Sector-60 Noida), Bangalore/Bengaluru(El...  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting naukri url\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search and entering Data Scientist in search bar\n",
    "search_tag = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_tag.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for click button\n",
    "search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filter for Delhi/NCR location\n",
    "location_filter = driver.find_elements_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "\n",
    "for i in location_filter:\n",
    "    if i.text == 'Delhi / NCR':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filter for salary\n",
    "Salary_filter = driver.find_elements_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "\n",
    "for i in Salary_filter:\n",
    "    if i.text == '3-6 Lakhs':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to scrap job details\n",
    "job_titles =[]\n",
    "company_names=[]\n",
    "Exp_list=[]\n",
    "loc_list=[]\n",
    "Package_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrating title tag, company tag, experience tag, location tag, package tag then the text of the job titls is inside the tags are extrated above \n",
    "# we will run a loop to itearate over the tags extracted above and extarct the text inside them\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[0:10]:\n",
    "        job_titles.append(i.text.replace('\\n','').strip())\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[0:10]:\n",
    "        company_names.append(j.text.replace('\\n','').strip())\n",
    "for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")[0:10]:\n",
    "        Exp_list.append(k.text.replace('\\n','').strip())\n",
    "for m in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")[0:10]:\n",
    "        loc_list.append(m.text.replace('\\n','').strip())\n",
    "for n in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")[0:10]:\n",
    "        Package_list.append(n.text.replace('\\n','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(Exp_list),len(loc_list),len(Package_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Framing Dataset\n",
    "import pandas as pd\n",
    "Data_Scientist_jobs=pd.DataFrame({})\n",
    "Data_Scientist_jobs['title']=job_titles\n",
    "Data_Scientist_jobs['company']=company_names\n",
    "Data_Scientist_jobs['experience_required']= Exp_list\n",
    "Data_Scientist_jobs['location']=loc_list\n",
    "Data_Scientist_jobs['Package']=Package_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "      <th>Package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Persistent Systems Limited.</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/APICS</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine/deep Learning Algorithms</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Image Processing/Machine Lear...</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Image Processing/ Machine Lea...</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning/Python</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Image Recognition/Machine Lea...</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Image Recognition/ Machine Le...</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3            Data Scientist - Machine Learning/APICS   \n",
       "4  Data Scientist - Machine/deep Learning Algorithms   \n",
       "5  Data Scientist - Image Processing/Machine Lear...   \n",
       "6  Data Scientist - Image Processing/ Machine Lea...   \n",
       "7           Data Scientist - Machine Learning/Python   \n",
       "8  Data Scientist - Image Recognition/Machine Lea...   \n",
       "9  Data Scientist - Image Recognition/ Machine Le...   \n",
       "\n",
       "                              company experience_required  \\\n",
       "0  Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1         Persistent Systems Limited.            8-13 Yrs   \n",
       "2                       Wipro Limited             4-9 Yrs   \n",
       "3                   CarbyneTech India             3-8 Yrs   \n",
       "4                   CarbyneTech India             3-8 Yrs   \n",
       "5                   CarbyneTech India            6-11 Yrs   \n",
       "6                   CarbyneTech India            6-11 Yrs   \n",
       "7                   CarbyneTech India             3-8 Yrs   \n",
       "8                   CarbyneTech India            5-10 Yrs   \n",
       "9                   CarbyneTech India            5-10 Yrs   \n",
       "\n",
       "                                            location                  Package  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  3,50,000 - 4,50,000 PA.  \n",
       "1  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru            Not disclosed  \n",
       "2  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...            Not disclosed  \n",
       "3                             Hyderabad/Secunderabad            Not disclosed  \n",
       "4                             Hyderabad/Secunderabad            Not disclosed  \n",
       "5                             Hyderabad/Secunderabad            Not disclosed  \n",
       "6                             Hyderabad/Secunderabad            Not disclosed  \n",
       "7                             Hyderabad/Secunderabad            Not disclosed  \n",
       "8                             Hyderabad/Secunderabad            Not disclosed  \n",
       "9                             Hyderabad/Secunderabad            Not disclosed  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping first 100 sunglasses listings on flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting with the Chrome Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Flipkart URL\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing Pop-ups if any \n",
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding lement for sunglasses and Entering Sun Glasses in the Search Bar\n",
    "search_tag = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_tag.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding element for Click Search Bar \n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List\n",
    "brand_list = []\n",
    "description_list = []\n",
    "price_list = []\n",
    "discount_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying for Loop for Brand tag, Product_Description tag, Price tag, Discount tag\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand_list.append(i.text)\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        description_list.append(j.text.replace('\\n',' '))\n",
    "for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price_list.append(k.text)\n",
    "for m in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount_list.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click to go next Page\n",
    "\n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Same for loop for 2nd Page\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand_list.append(i.text)\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        description_list.append(j.text.replace('\\n',' '))\n",
    "for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price_list.append(k.text)\n",
    "for m in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount_list.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to 3rd Page\n",
    "\n",
    "driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[4]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying for Loop for Brand tag, Product_Description tag, Price tag, Discount tag\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand_list.append(i.text)\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        description_list.append(j.text.replace('\\n',' '))\n",
    "for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price_list.append(k.text)\n",
    "for m in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount_list.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click to go next Page\n",
    "\n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying for loop for 3rd Page Data\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand_list.append(i.text)\n",
    "for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        description_list.append(j.text.replace('\\n',' '))\n",
    "for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price_list.append(k.text)\n",
    "for m in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount_list.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Wayfarer Su...</td>\n",
       "      <td>₹516</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹570</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹592</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (F...</td>\n",
       "      <td>₹1,110</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Shield Sung...</td>\n",
       "      <td>₹516</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (57)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0           AISLIN  UV Protection, Gradient Butterfly, Wayfarer Su...    ₹516   \n",
       "1        ROYAL SON         UV Protection Retro Square Sunglasses (88)    ₹599   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹570   \n",
       "3   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹499   \n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹499   \n",
       "..             ...                                                ...     ...   \n",
       "95          AISLIN  UV Protection, Gradient Butterfly, Retro Squar...    ₹592   \n",
       "96        Fastrack  Polarized, UV Protection Aviator Sunglasses (F...  ₹1,110   \n",
       "97          AISLIN  UV Protection, Gradient Butterfly, Shield Sung...    ₹516   \n",
       "98  ROZZETTA CRAFT    UV Protection, Gradient Aviator Sunglasses (57)    ₹449   \n",
       "99  ROZZETTA CRAFT  UV Protection, Gradient Butterfly, Retro Squar...    ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   66% off  \n",
       "1   70% off  \n",
       "2   28% off  \n",
       "3   77% off  \n",
       "4   77% off  \n",
       "..      ...  \n",
       "95  72% off  \n",
       "96  14% off  \n",
       "97  66% off  \n",
       "98  77% off  \n",
       "99  85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Data into DataFrame\n",
    "\n",
    "Sunglasses_100 = pd.DataFrame({})\n",
    "\n",
    "Sunglasses_100['Brand'] = brand_list[:100]\n",
    "Sunglasses_100['Product Description'] = description_list[:100]\n",
    "Sunglasses_100[\"Price\"] = price_list[:100]\n",
    "Sunglasses_100['Discount'] = discount_list[:100]\n",
    "\n",
    "Sunglasses_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping iphone reviews from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting with the Chrome Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting URL\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting All Reviews\n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List to Scrape data into it\n",
    "Rating = []\n",
    "Review_Summary = []\n",
    "Full_Review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying for loop for first 11 pages to scrape data from it\n",
    "\n",
    "for i in range(0,11):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review_Summary.append(k.text.replace('\\n',' '))\n",
    "    for m in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        Full_Review.append(m.text.replace('\\n',' '))\n",
    "    for n in driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\"):\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span[2]\")\n",
    "        except:\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110 110\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_Summary),len(Full_Review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  I’m am v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️ Its awesome mobile phone i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5       Great product   \n",
       "3       5   Worth every penny   \n",
       "4       4         Good choice   \n",
       "..    ...                 ...   \n",
       "95      5  Highly recommended   \n",
       "96      5           Fabulous!   \n",
       "97      5    Perfect product!   \n",
       "98      5    Perfect product!   \n",
       "99      5   Worth every penny   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money  The iPhone 11 of...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.  I’m am v...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  iphone 11 is a very good phone to buy only if ...  \n",
       "96  This is my first iOS phone. I am very happy wi...  \n",
       "97  It’s a must buy who is looking for an upgrade ...  \n",
       "98  Value for money❤️❤️ Its awesome mobile phone i...  \n",
       "99  Best budget Iphone till date ❤️ go for it guys...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Framing dataset\n",
    "\n",
    "Iphone_Reviews = pd.DataFrame({})\n",
    "\n",
    "Iphone_Reviews['Rating'] = Rating[:100]\n",
    "Iphone_Reviews['Review Summary'] = Review_Summary[:100]\n",
    "Iphone_Reviews['Full Review'] = Full_Review[:100]\n",
    "\n",
    "Iphone_Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping data for first 100 sneakers from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting with the Chrome Driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening Flipkart URL\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing Pop-ups if any \n",
    "\n",
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering Sneakers in the Search Bar\n",
    "\n",
    "search_tag = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_tag.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click Search Bar Option\n",
    "\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List to Scrape data into it\n",
    "\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying for loop for first 4 pages to scrape data from it\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        Brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        Product_Description.append(k.text.replace('\\n',' '))\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        Price.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        Discount.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']/span\"):\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span[2]\").click()\n",
    "        except:\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\").click()\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 141 160 160\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>shoes for boys Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otoos</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹418</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VIPSJAZZY</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jokatoo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹423</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>ORIFWSH(OR)-1077 Sneakers For Men</td>\n",
       "      <td>₹2,063</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Simha IDP Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Birde</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹471</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product Description   Price  \\\n",
       "0          Echor                    shoes for boys Sneakers For Men    ₹599   \n",
       "1          otoos                                   Sneakers For Men    ₹418   \n",
       "2       Magnolia                                   Sneakers For Men    ₹356   \n",
       "3   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men    ₹379   \n",
       "4      VIPSJAZZY  Combo pack of 2 casual sneaker shoes for men S...    ₹419   \n",
       "..           ...                                                ...     ...   \n",
       "95        DUCATI                          Sneakers Sneakers For Men  ₹1,399   \n",
       "96       Jokatoo                                   Sneakers For Men    ₹423   \n",
       "97      Skechers                  ORIFWSH(OR)-1077 Sneakers For Men  ₹2,063   \n",
       "98          aadi                         Simha IDP Sneakers For Men    ₹298   \n",
       "99         Birde                                   Sneakers For Men    ₹471   \n",
       "\n",
       "   Discount  \n",
       "0   40% off  \n",
       "1   58% off  \n",
       "2   64% off  \n",
       "3   62% off  \n",
       "4   58% off  \n",
       "..      ...  \n",
       "95  61% off  \n",
       "96  71% off  \n",
       "97  52% off  \n",
       "98  70% off  \n",
       "99  52% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers100 = pd.DataFrame({})\n",
    "\n",
    "Sneakers100['Brand'] = Brand[:100]\n",
    "Sneakers100['Product Description'] = Product_Description[:100]\n",
    "Sneakers100[\"Price\"] = Price[:100]\n",
    "Sneakers100['Discount'] = Discount[:100]\n",
    "\n",
    "Sneakers100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping First 100 shoes data from myntra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activating chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shoe_Brand = []\n",
    "Shoe_Description = []\n",
    "Shoe_Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    \n",
    "    for j in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        Shoe_Brand.append(j.text)\n",
    "        \n",
    "    for k in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        Shoe_Description.append(k.text.replace('\\n',' '))\n",
    "     \n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='product-price']\"):\n",
    "        var=l.text.split('Rs.')[1].strip()\n",
    "        Shoe_Price.append(var)\n",
    "     \n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']\").click()\n",
    "    \n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Shoe_Brand),len(Shoe_Description),len(Shoe_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe_Brand</th>\n",
       "      <th>Shoe_Description</th>\n",
       "      <th>Shoe_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Solid Leather Formal Loafers</td>\n",
       "      <td>6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>10920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Men Nano X1 Training Shoes</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Adizero Ubersonic 4 Tennis</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>12495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shoe_Brand                   Shoe_Description Shoe_Price\n",
       "0      Florsheim   Men Solid Leather Formal Loafers       6995\n",
       "1   Hush Puppies  Men Solid Leather Formal Slip-Ons       8999\n",
       "2          Ruosh    Men Solid Leather Formal Derbys       8990\n",
       "3           ALDO                       Men Sneakers       9999\n",
       "4           Nike     AIR ZOOM PEGASUS Running Shoes      10920\n",
       "..           ...                                ...        ...\n",
       "95        Reebok         Men Nano X1 Training Shoes       6999\n",
       "96  Hush Puppies    Men Solid Leather Formal Derbys       9999\n",
       "97        ADIDAS     Men Adizero Ubersonic 4 Tennis      10499\n",
       "98  Kenneth Cole             Women Solid Flat Boots       9513\n",
       "99          Nike        Women AIR MAX VIVA Sneakers      12495\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Black_Shoe100 = pd.DataFrame({})\n",
    "\n",
    "Black_Shoe100['Shoe_Brand'] = Shoe_Brand\n",
    "Black_Shoe100['Shoe_Description'] = Shoe_Description\n",
    "Black_Shoe100['Shoe_Price'] = Shoe_Price\n",
    "\n",
    "Black_Shoe100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping laptop data from amazon by appling CPU filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activating chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\BHAVANI\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product you want to search: laptop\n"
     ]
    }
   ],
   "source": [
    "#opening the homepage of Amazon.in\n",
    "driver.get('https://www.amazon.in')\n",
    "#asking the user ti input the keywords he/she wants to search\n",
    "\n",
    "use_inp=input('Enter the product you want to search: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\") #locating search_bar by id\n",
    "search_bar.clear()  #clearing search bar\n",
    "search_bar.send_keys(use_inp)  #sending user input to search bar\n",
    "time.sleep(4)\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input') #locating search bar by path\n",
    "search_button.click() #clicking the button to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "titles=[]\n",
    "ratings=[]\n",
    "prices=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")[0:10]:\n",
    "    titles.append(j.text)\n",
    "for k in driver.find_elements_by_xpath(\"//i[@data-hook='a-icon a-icon-star-small a-star-small-4-5 aok-align-bottom']\")[0:10]:\n",
    "    ratings.append(k.get_attribute(\"span\"))\n",
    "for m in driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")[0:10]:\n",
    "    prices.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.56cms) Full HD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Fingerprint Reader/Slate Grey/Aluminium Surface/1.43Kg), 82BH004HIN',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " '(Renewed) Dell Latitude E6420 14 Inch Laptop (Core I7 2460M/4GB/320GB/Nvidia Dedicated Graphics/Windows Professional/MS Office), Dark Grey',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 8GB RAM, 512GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " '(Renewed) Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'Lenovo ThinkPad E14 Intel Core i7 10th Gen14-inch Full HD IPS Thin and Light Laptop (16GB RAM/ 1TB HDD+256GB SSD/ Windows 10 Home/ Microsoft Office Home & Student 2019/ Black/ 1.69kg), 20RAS0AM00']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93,740',\n",
       " '1,07,990',\n",
       " '53,219',\n",
       " '35,000',\n",
       " '29,990',\n",
       " '84,490',\n",
       " '4,13,890',\n",
       " '21,592',\n",
       " '87,990',\n",
       " '46,290']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
